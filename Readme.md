# 딥러닝을 이용한 신문 요약

  본 프로젝트는 2021년 상반기 창원대학교 졸업작품을 위해 개설되었으며 딥러닝 기반 자연어 처리 모델인 M3를 이용하여 신문, 뉴스 기사를 요약하는 모델을 구축하고자 한다.

### History

| 날짜       | 내용                | 작성자 |
| ---------- | ------------------- | ------ |
| 2021.03.15 | Readme.md 초안 작성 | 정민수 |

### 개발 환경

* Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-129-generic x86_64)
* Python 3.7.9
* Pytorch 1.7.1
* Conda 4.9.0

## 목차

* [1. 신문 요약](#1-신문-요약)
  * [1.1. 자연어 처리 개요](#11-자연어-처리-개요)
  * [1.2. 문서 요약](12-문서-요약)
  * [1.3. 신문 요약](#13-신문-요약)
* [2. 데이터셋](#2-데이터셋)
  * [2.1. 데이터셋 요약](#21-데이터셋-요약)
  * [2.2. 추가 데이터셋](#22-추가-데이터셋)
* [3. M3 모델](#3-m3-모델)
  * [3.1. M3 모델 전체 구조](#31-m3-모델-전체-구조)
  * [3.2. 인코더](#32-인코더)
  * [3.3. 디코더](#33-디코더)

## 1. 신문 요약

### 1.1. 자연어 처리 개요

  자연어 처리(Natural Language Processing, NLP)는 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 묘사할 수 있도록 연구하고 이를 구현하는 인공지능의 주요 분야 중 하나다. 자연 언어 처리는 연구 대상이 언어이기 때문에 당연하게도 언어 자체를 연구하는 언어학과 언어 현상의 내적 기재를 탐구하는 언어 인지 과학과 연관이 깊다. 구현을 위해 수학적 통계적 도구를 많이 활용하며 특히 기계학습 도구를 많이 사용하는 대표적인 분야이다. 정보 검색, QA 시스템, 문서 자동 분류, 신문기사 클러스터링, 대화형 Agent 등 다양한 응용이 이루어지고 있다.

> 내용 출처: [https://ko.wikipedia.org/wiki/%EC%9E%90%EC%97%B0%EC%96%B4_%EC%B2%98%EB%A6%AC](https://ko.wikipedia.org/wiki/자연어_처리)

### 1.2. 문서 요약

  텍스트 데이터를 수집하여, 필요한 정보를 압축해서 정보를 제공하는 형태를 문서 요약(Text Summarization)이라고 한다. 문서를 자동으로 요약하는 방법은 크게 추출(Extraction)과 생성(Abstraction)으로 구분한다.

* 추출(Extraction): 문서 내 문장 구조의 중요도를 기반으로 요소를 그대로 발췌하는 방식으로 보다 쉬운 접근 방법이지만 요약문의 응집도나 가독성이 부족할 수 있다.
* 생성(Abstraction): 자연어 처리 기반을 통해 원 문서 요소를 재조합하여 새로운 문장을 구성하는 방식으로 자연어를 이해하고 생성하는 기술이 필수적이다.

> 내용 출처: https://jaydata.tistory.com/75

### 1.3. 신문 요약

  이 프로젝트에서 진행할 내용은 다음과 같다.

* 신문 요약을 위한 데이터셋 구축
* 자연어 처리 모델 중 하나인 M3가 뉴스 기사를 요약할 수 있도록 학습

## 2. 데이터셋

### 2.1. 데이터셋 요약

| 출처          | 문서 수    | 크기 | 설명                                                   |
| ------------- | ---------- | ---- | ------------------------------------------------------ |
| 모두의 말뭉치 | 4,387 문서 | 22M  | 모두의 말뭉치에서 공개한 데이터 중 문서 요약 데이터 셋 |
| -             | 2,000 문서 | 6.9M | 크롤링한 뉴스를 사람이 직접 요약하여 만든 데이터 셋    |

### 2.2. 추가 데이터셋

| 출처     | 문서 수      | 크기 | 설명                                                     |
| -------- | ------------ | ---- | -------------------------------------------------------- |
| 인사이트 | 222,082 문서 | 443M | 인사이트 뉴스를 크롤링하여 구축한 데이터 셋([아래] 참조) |

**인사이트 크롤링 데이터셋**

| 추출한 칼럼 | 설명                                                |
| ----------- | --------------------------------------------------- |
| index       | 뉴스 기사의 순서 (https://insight.com/news/[index]) |
| title       | 뉴스 기사 제목                                      |
| date        | 뉴스 게시일                                         |
| class       | 뉴스 기사 분류 카테고리                             |
| section     | 인사이트 상에서의 기사 카테고리                     |
| keywords    | 뉴스 기사 핵심 키워드                               |
| summary     | 뉴스 요약문                                         |
| content     | 뉴스 원문                                           |

**인사이트 크롤링 데이터셋 예시**

```json
[
  {
    "index": 151598,
    "title": "아티스, “주가 급등 관련, 공시 사항 없다” - 인사이트",
    "date": "2018-04-23 16:40:24",
    "class": "Public Notice, 공시",
    "section": "공시",
    "keywords": "아티스, “주가 급등 관련, 공시 사항 없다”",
    "summary": "아티스(2,595원 상승165 -6.0%)는 현저한 주가 급등에 관련 조회공시 요구에 대해 “공시할 정보가 없다”고 23일 공시했다.",
    "content": "\n[인사이트] 이유리 기자 = 아티스(2,595원 상승165 -6.0%)는 현저한 주가 급등에 관련 조회공시 요구에 대해 \"공시할 정보가 없다\"고 23일 공시했다. 회사측은  \"수익구조 개선을 위해 여러 가지 방안을 구상중이나 진행중인 사항은 없으며 추후 공시의무사항이 발생하면 즉시 공시할 것\"이라고 밝혔다.  "
  },
  {
    "index": 151599,
    "title": "‘여사친’이 휴대폰 만지는 사이 몰래 ‘데이트 강간’ 약물 넣어 성폭행한 남성 - 인사이트",
    "date": "2018-04-23 16:44:00",
    "class": "World, 국제",
    "section": "국제",
    "keywords": "‘여사친’이 휴대폰 만지는 사이 몰래 ‘데이트 강간’ 약물 넣어 성폭행한 남성",
    "summary": "평소 친했던 친구에게 몰래 약물을 먹여 성폭행을 저지른 남성이 경찰에 붙잡혔다.",
    "content": "\nWeibo[인사이트] 황비 기자 = 친구가 한눈을 판 사이 음료에 몰래 데이트 강간 약물을 넣는 남성의 모습이 포착돼 충격을 안겼다.\r\n지난 21일(현지 시간) 중국 웨이보는 친구에게 약물을 먹여 성폭행한 남성 구 모우(Gu Mou)가 경찰에 체포됐다고 보도했다.\r\n최근 중국 상하이 바오산에 사는 남성 모우는 친한 친구인 첸(Chen)과 저녁 식사를 함께했다.\r\nWeibo두 사람은 1년 전부터 연락을 주고받고 함께 식사를 하는 등 가깝게 지냈지만 사귀는 사이는 아니었다.\r\n첸과 친구 이상의 사이가 되고 싶었지만 뜻대로 되지 않자 모우는 범죄를 계획했다.\r\n식사 중 첸이 휴대폰 게임에 정신이 팔린 사이 모우는 첸의 컵에 몰래 약을 탔다.\r\n잠시 후 첸이 약에 취해 어지러움을 호소하고 제대로 걷지 못하자 모우는 첸을 데리고 미리 예약해둔 호텔로 향했다.\r\nWeibo다음날 깨어난 첸은 자신이 성폭행을 당했음을 깨닫고 곧바로 경찰에 신고 전화를 걸었다.\r\n사건을 수사하던 경찰은 식당 CCTV에서 범행의 순간을 잡아냈다.\r\n잠깐의 방심한 틈을 타 약을 타는 모우의 모습에 경찰도 혀를 내둘렀다.\r\n바오산 지역 경찰은 \"안타까운 일이지만 외출시 항상 주의를 기울여야 한다\"며 \"내 음식에 누가 손을 대지 않는지 유의하는 것이 모우같은 범죄자들에게 기회를 주지 않는 길이다\"고 주의를 당부했다.\r\n현재 모우는 강간 혐의로 경찰에 체포된 상태다. "
  },
  {
    "index": 151600,
    "title": "CJ월디스, 웨딩 시즌을 겨냥 ‘허니문 여행 박람회’ 오픈 - 인사이트",
    "date": "2018-04-23 16:44:30",
    "class": "Consumer, 소비자",
    "section": "소비자",
    "keywords": "CJ월디스, 웨딩 시즌을 겨냥 ‘허니문 여행 박람회’ 오픈",
    "summary": "CJ월디스가 웨딩 시즌을 겨냥하여 인기 허니문 상품을 모아 허니문 여행 박람회를 오픈했다.",
    "content": "\n자신제공 = cj월디스[인사이트] 김민수 기자 = CJ월디스가 웨딩 시즌을 겨냥하여 인기 허니문 상품을 모아 허니문 여행 박람회를 오픈했다고 밝혔다. \r\n23일부터 진행되는 허니문 여행 박람회에서는 CJ월디스를 비롯해 Otour, 하나투어, 모두투어 등 공신력 있는 여행사들의 허니문 상품을 모아 선보이며 각 여행사 별로 예약 고객 대상 특전을 제공한다. \r\n각 여행사별 혜택으로 CJ월디스는 여행팩 햇반컵반 세트, 인천공항 Air Town 식사권, 런닝맨 체험관 초대권, CJ월디스 여행 이용권 5만원권을 증정한다.\r\n사진제공 = cj월디스여기에 모두투어는 신세계 이마트 상품권 최대 10만원 증정, 하나투어 여행상품권 5만원을 증정한다. \r\nCJ월디스만의 맞춤 허니문 상담도 준비되어 있다. 원하는 지역, 일정들을 담당자에게 전달 및 상담을 신청하면 전문 상담사가 일대일 맞춤 허니문을 설계해준다. \r\n이벤트 기간 내 맞춤 허니문 상담 진행 및 예약 결제를 진행한 예비 허니무너들에게는 SM면세점 선불카드가 증정된다. \r\n사진제공 = cj월디스또한 허니문 박람회 동안에 모든 상품을 예약한 고객에게는 CJ월디스와 CJmall에서만 누릴 수 있는 혜택을 제공한다. \r\nCJmall 적립금 10만원 제공, 최대 10개월 무이자 할부, 카드사별 최대 7% 청구 할인까지 받을 수 있다 \r\nSNS 소문내기 이벤트가 박람회 기간 동안 함께 진행하여 추첨을 통해 다이슨 청소기, CJ월디스 이용권, 투썸 아메리카노를 증정하며 해당 이벤트는 오투어 홈페이지를 통해 참여 가능하다. "
  }
]
```



## 3. M3 모델

  이 프로젝트에선 자연어 처리 모델로 M3를 사용한다.

### 3.1. M3 모델 전체 구조

  M3(Multimodal-to-Multimodal Transformer with External Memory) 모델은 기본적으로 트랜스포머 인코더-디코더 구조를 따른다.

<img src = "https://tva1.sinaimg.cn/large/008eGmZEgy1gon59vrn1nj30io0pg75t.jpg" width=50%>

> 사진 출처: [Attention Is All You Need 논문(Figure 1)](https://arxiv.org/pdf/1706.03762.pdf)

### 3.2. 인코더

* **Input Embedding:** 입력과 가중치(Weight)의 행렬 연산을 위해 입력된 문서를 수치화시켜주는 과정이 필요하다. 임베딩(Embedding)은 입력된 문서를 적절한 토큰 단위로 자르고 각 토큰을 정해진 차원만큼의 실수로 변경한다.
  * 예) 강아지 = [0.2, 1.8, 1.1, -2.1, 1.1, 2.8, ...] # 128차원의 벡터

* **Positional Encoding:** 텍스트에서 어순은 언어를 이해하는 데 중요한 역할을 하기에 이 정보에 대한 처리가 필요하다. 포지셔널 인코딩(Positional Encoding)은 임베딩 벡터에 위치 정보를 부여하는 과정이다.
* **Multi-Head Attention:** [TODO] Write this.
* **Add & Norm:** 연산된 결과를 정규화시키는 과정이다. 벡터 값이나 가중치가 과하게 튀지 않게 방지하고 수치가 작은 값이라도 적절히 사용되도록 만든다.
* **Feed Forward: ** 은닉층의 가중치를 연산하고 결과를 생성하는 계층이다. 이 계층을 거치고 나오는 출력은 입력된 문서의 정보를 압축한 결과가 된다.

### 3.3. 디코더

* **Output Embedding:** 학습을 위해 정답으로 입력된 텍스트 데이터를 임베딩하는 과정이다. Input Embedding과 유사하지만 태스크에 따라 적절히 마스킹(Masking) 되거나 특별 토큰 하나만으로 이루어질 수도 있다.

* **Masked Multi-Head Attention:** [TODO] Write this.
* **Linear, Softmax:** 연산된 결과를 바탕으로 새로운 토큰을 예측한다.



[TODO] Write this.

